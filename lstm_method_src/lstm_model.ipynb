{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # label数组变为one-hot编码\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, CuDNNLSTM, CuDNNGRU\n",
    "from keras.layers import Reshape, Merge, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam # Adam 优化，加速收敛\n",
    "\n",
    "from sklearn.model_selection import train_test_split # 用于划分训练集和验证集\n",
    "from process_data import process_data # 按题目对数据处理\n",
    "from label_data import get_labeled_data # 获取带标签的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 数据输入与预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 得到训练集测试集并统计各类别数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到dat_name类作为输入,lab_name类作为标记涨落的训练数据和测试数据\n",
    "def get_train_test(dat_name, lab_name):\n",
    "    train_x, train_y = get_labeled_data(dat_name, lab_name, 'train_')\n",
    "    test_x, test_y = get_labeled_data(dat_name, lab_name, 'test_')\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于训练数据本来比较少,故从测试集合中划分0.2作为validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_val_test(test_x, test_y):\n",
    "    test_x, val_x, test_y, val_y = train_test_split(test_x, \n",
    "                                                    test_y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 2)\n",
    "    return val_x, val_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取训练与测试数据,并统计各类别有多少样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_category_num(ys, k = 3):\n",
    "    tmp = [0 for i in range(k)]\n",
    "    for lab in ys:\n",
    "        tmp[int(lab)] += 1\n",
    "    print(tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注:\n",
    "\n",
    "1. 通过第一次作业可视化对数据的观察,发现A的两个类别数据相关性较大,所以可以考虑当预测A1时,将前五分钟的A1和A3价格一并作为训练数据\n",
    "2. 考虑训练一个A1关于A1历史价格的模型,训练一个A1关于A3历史价格的模型,模型组合进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "[1402, 53151, 1412]\n",
      "validation:\n",
      "[183, 7123, 185]\n",
      "test:\n",
      "[679, 28596, 685]\n"
     ]
    }
   ],
   "source": [
    "train_x1, train_y1, test_x1, test_y1 = get_train_test('A1', 'A1')\n",
    "train_x2, train_y2, test_x2, test_y2 = get_train_test('A3', 'A1')\n",
    "val_x1, val_y1, test_x1, test_y1 = split_val_test(test_x1, test_y1)\n",
    "val_x2, val_y2, test_x2, test_y2 = split_val_test(test_x2, test_y2)\n",
    "print('train:')\n",
    "train_details = count_category_num(train_y1)\n",
    "print('validation:')\n",
    "val_details = count_category_num(val_y1)\n",
    "print('test:')\n",
    "test_details = count_category_num(test_y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 特征提取\n",
    "\n",
    "1. 使用相邻点相减得到变化率(导数)向量\n",
    "2. 对变化率相邻点相减得到变化的快慢(二阶导数)\n",
    "3. 使用mean-pooling对导数和二阶导数进行\"降维\"\n",
    "4. 池化降维后的导数向量记为$[f_1^1, f_1^2, f_1^3, \\cdots, f_1^n]$, 二阶导数向量记为$[f_2^1, f_2^2, f_2^3, \\cdots, f_2^n]$\n",
    "4. 导数与二阶导数间隔排列组成特征向量$[f_1^1, f_2^1, f_1^2, f_2^2, \\cdots, f_1^n, f_2^n]$,它保持了时序性,为后续LSTM的应用做好了准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mean_pooling(dat):\n",
    "    ret = np.zeros((dat.shape[0], dat.shape[1] // 2))\n",
    "    for i in range(ret.shape[1]):\n",
    "        ret[:, i] = (dat[:, 2*i]+dat[:, 2*i+1]) / 2\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导数\n",
    "train_dx_1 = convolve2d(train_x1, [[1, -1]], mode = 'same', boundary = 'fill')\n",
    "val_dx_1 = convolve2d(val_x1, [[1, -1]], mode = 'same', boundary = 'fill')\n",
    "test_dx_1 = convolve2d(test_x1, [[1, -1]], mode = 'same', boundary = 'fill')\n",
    "# 二阶导数\n",
    "train_dx2_1 = convolve2d(train_dx_1, [[1, -1]], mode = 'same', boundary = 'fill')\n",
    "val_dx2_1 = convolve2d(val_dx_1, [[1, -1]], mode = 'same', boundary = 'fill')\n",
    "test_dx2_1 = convolve2d(test_dx_1, [[1, -1]], mode = 'same', boundary = 'fill')\n",
    "# 对二者池化\n",
    "train_dx_1 = mean_pooling(train_dx_1)\n",
    "val_dx_1 = mean_pooling(val_dx_1)\n",
    "test_dx_1 = mean_pooling(test_dx_1)\n",
    "train_dx2_1 = mean_pooling(train_dx2_1)\n",
    "val_dx2_1 = mean_pooling(val_dx2_1)\n",
    "test_dx2_1 = mean_pooling(test_dx2_1)\n",
    "\n",
    "\n",
    "train_dx_2 = convolve2d(train_x2, [[1, -1]], mode = 'same', boundary = 'fill')\n",
    "val_dx_2 = convolve2d(val_x2, [[1, -1]], mode = 'same', boundary = 'fill')\n",
    "test_dx_2 = convolve2d(test_x2, [[1, -1]], mode = 'same', boundary = 'fill')\n",
    "\n",
    "train_dx2_2 = convolve2d(train_dx_2, [[1, -1]], mode = 'same', boundary = 'fill')\n",
    "val_dx2_2 = convolve2d(val_dx_2, [[1, -1]], mode = 'same', boundary = 'fill')\n",
    "test_dx2_2 = convolve2d(test_dx_2, [[1, -1]], mode = 'same', boundary = 'fill')\n",
    "\n",
    "train_dx_2 = mean_pooling(train_dx_2)\n",
    "val_dx_2 = mean_pooling(val_dx_2)\n",
    "test_dx_2 = mean_pooling(test_dx_2)\n",
    "train_dx2_2 = mean_pooling(train_dx2_2)\n",
    "val_dx2_2 = mean_pooling(val_dx2_2)\n",
    "test_dx2_2 = mean_pooling(test_dx2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dat(dx, dx2):\n",
    "    x = np.zeros((dx.shape[0], dx.shape[1]*2))\n",
    "    for i in range(dx.shape[1]):\n",
    "        x[:, 2*i] = dx[:, i]\n",
    "        x[:, 2*i+1] = dx2[:, i]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = merge_dat(train_dx_1, train_dx2_1)\n",
    "val_1 = merge_dat(val_dx_1, val_dx2_1)\n",
    "test_1 = merge_dat(test_dx_1, test_dx2_1)\n",
    "\n",
    "train_2 = merge_dat(train_dx_2, train_dx2_2)\n",
    "val_2 = merge_dat(val_dx_2, val_dx2_2)\n",
    "test_2 = merge_dat(test_dx_2, test_dx2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 重平衡训练数据并统计样本数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采取去掉\"不变\"类别的训练数据进行平衡的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance_data(xs, ys, k, ratio_list, seed = 2):\n",
    "    nums = [0 for i in range(k)]\n",
    "    for i in range(len(ys)):\n",
    "        nums[int(ys[i])] += 1\n",
    "    tot = int(min([nums[i] / ratio_list[i] for i in range(k)]))\n",
    "    new_nums = [round(tot * ratio_list[i]) for i in range(k)]\n",
    "    drop_ratio = [(nums[i] - new_nums[i])/nums[i] for i in range(k)]\n",
    "    np.random.seed(seed)\n",
    "    select_list = [ i for i in range(len(ys)) if not np.random.rand() < drop_ratio[int(ys[i])] ]\n",
    "    ret_xs = xs[select_list]\n",
    "    ret_ys = ys[select_list]\n",
    "    return ret_xs, ret_ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照3:4:3重平衡数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_train_x1, bal_train_y1 = rebalance_data(train_1, train_y1, 3, [0.3, 0.4, 0.3])\n",
    "bal_train_x2, bal_train_y2 = rebalance_data(train_2, train_y2, 3, [0.3, 0.4, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印训练数据的三类样本数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1402, 1878, 1400]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1402, 1878, 1400]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_category_num(bal_train_y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 定义输出正确率，召回率函数用于测试的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_result(label, predict, k = 3):\n",
    "    mat = [[0 for j in range(k)] for i in range(k)]\n",
    "    for i in range(len(label)):\n",
    "        mat[int(label[i])][int(predict[i])] += 1\n",
    "    correct_mat = np.array(mat)\n",
    "    precision = [0,0,0]\n",
    "    recall = [0,0,0]\n",
    "    for i in range(3):\n",
    "        precision[i] = correct_mat[i][i] / (correct_mat[0][i] + correct_mat[1][i] + correct_mat[2][i])\n",
    "        recall[i] = correct_mat[i][i] / (correct_mat[i][0] + correct_mat[i][1] + correct_mat[i][2])\n",
    "    print(\"precision : \", precision)\n",
    "    print(\"recall : \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 把标签转换为one-hot格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab = to_categorical(train_y1, 3)\n",
    "test_lab = to_categorical(test_y1, 3)\n",
    "val_lab = to_categorical(val_y1, 3)\n",
    "bal_train_lab = to_categorical(bal_train_y1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 模型的训练\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 单一模型的结构\n",
    "\n",
    "- 采用GRU->LSTM->BatchNorm->Dense->Dropout->Softmax的网络结构, 建立A1价格变化关于A1历史价格的模型和A1价格变化关于A3历史价格的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIT_SIZE_1 = 30\n",
    "UNIT_SIZE_2 = 30\n",
    "TIME_STEPS = 40\n",
    "INPUT_SIZE = 15\n",
    "OUTPUT_SIZE = 3\n",
    "\n",
    "#在这里规定model的结构\n",
    "def model_structure(model):\n",
    "    model.add(Reshape((TIME_STEPS, INPUT_SIZE), input_shape=(600,)))\n",
    "    model.add(CuDNNGRU(units = UNIT_SIZE_1, return_sequences=True))\n",
    "    model.add(CuDNNLSTM(units = UNIT_SIZE_2, return_sequences=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(OUTPUT_SIZE, activation = 'softmax'))\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两种模型采用相同的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_15 (Reshape)         (None, 40, 15)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_15 (CuDNNGRU)      (None, 40, 30)            4230      \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_15 (CuDNNLSTM)    (None, 30)                7440      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                1984      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 13,969\n",
      "Trainable params: 13,909\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_2 = Sequential()\n",
    "model_structure(model_1)\n",
    "model_structure(model_2)\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 两个单一模型分别训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A1价格变化关于A1历史价格的模型(训练)\n",
    "\n",
    "- 从训练结果可以看出最终在训练集和验证集上正确率均能达到70%左右, 模型是有效的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4680 samples, validate on 7491 samples\n",
      "Epoch 1/50\n",
      "4680/4680 [==============================] - 4s 816us/step - loss: 1.1720 - acc: 0.4162 - val_loss: 0.6492 - val_acc: 0.7355\n",
      "Epoch 2/50\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 1.0386 - acc: 0.4474 - val_loss: 0.5926 - val_acc: 0.7712\n",
      "Epoch 3/50\n",
      "4680/4680 [==============================] - 2s 447us/step - loss: 1.0031 - acc: 0.4654 - val_loss: 0.5806 - val_acc: 0.7749\n",
      "Epoch 4/50\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.9787 - acc: 0.4897 - val_loss: 0.6064 - val_acc: 0.7724\n",
      "Epoch 5/50\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.9680 - acc: 0.5028 - val_loss: 0.5902 - val_acc: 0.7819\n",
      "Epoch 6/50\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.9531 - acc: 0.5098 - val_loss: 0.5934 - val_acc: 0.7812\n",
      "Epoch 7/50\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.9453 - acc: 0.5156 - val_loss: 0.5960 - val_acc: 0.7833\n",
      "Epoch 8/50\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.9357 - acc: 0.5344 - val_loss: 0.6139 - val_acc: 0.7780\n",
      "Epoch 9/50\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.9190 - acc: 0.5400 - val_loss: 0.5615 - val_acc: 0.7951\n",
      "Epoch 10/50\n",
      "4680/4680 [==============================] - 2s 454us/step - loss: 0.9142 - acc: 0.5541 - val_loss: 0.5856 - val_acc: 0.7717\n",
      "Epoch 11/50\n",
      "4680/4680 [==============================] - 2s 451us/step - loss: 0.9090 - acc: 0.5543 - val_loss: 0.5534 - val_acc: 0.8079\n",
      "Epoch 12/50\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.8943 - acc: 0.5622 - val_loss: 0.6051 - val_acc: 0.7744\n",
      "Epoch 13/50\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.8903 - acc: 0.5733 - val_loss: 0.5284 - val_acc: 0.8088\n",
      "Epoch 14/50\n",
      "4680/4680 [==============================] - 2s 451us/step - loss: 0.8771 - acc: 0.5652 - val_loss: 0.5510 - val_acc: 0.8031\n",
      "Epoch 15/50\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.8789 - acc: 0.5761 - val_loss: 0.5692 - val_acc: 0.7793\n",
      "Epoch 16/50\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.8639 - acc: 0.5906 - val_loss: 0.6380 - val_acc: 0.7485\n",
      "Epoch 17/50\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.8487 - acc: 0.5949 - val_loss: 0.5898 - val_acc: 0.7665\n",
      "Epoch 18/50\n",
      "4680/4680 [==============================] - 2s 449us/step - loss: 0.8326 - acc: 0.6060 - val_loss: 0.7198 - val_acc: 0.7051\n",
      "Epoch 19/50\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.8385 - acc: 0.6075 - val_loss: 0.6247 - val_acc: 0.7524\n",
      "Epoch 20/50\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.8334 - acc: 0.6105 - val_loss: 0.6067 - val_acc: 0.7522\n",
      "Epoch 21/50\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.8249 - acc: 0.6139 - val_loss: 0.5923 - val_acc: 0.7729\n",
      "Epoch 22/50\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.8056 - acc: 0.6357 - val_loss: 0.6359 - val_acc: 0.7444\n",
      "Epoch 23/50\n",
      "4680/4680 [==============================] - 2s 451us/step - loss: 0.8037 - acc: 0.6346 - val_loss: 0.6231 - val_acc: 0.7577\n",
      "Epoch 24/50\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.7962 - acc: 0.6402 - val_loss: 0.7757 - val_acc: 0.6952\n",
      "Epoch 25/50\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.7944 - acc: 0.6365 - val_loss: 0.7562 - val_acc: 0.6950\n",
      "Epoch 26/50\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.7879 - acc: 0.6425 - val_loss: 0.6588 - val_acc: 0.7393\n",
      "Epoch 27/50\n",
      "4680/4680 [==============================] - 2s 455us/step - loss: 0.7723 - acc: 0.6551 - val_loss: 0.8442 - val_acc: 0.6751\n",
      "Epoch 28/50\n",
      "4680/4680 [==============================] - 2s 449us/step - loss: 0.7679 - acc: 0.6600 - val_loss: 0.6630 - val_acc: 0.7484\n",
      "Epoch 29/50\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.7606 - acc: 0.6598 - val_loss: 0.7713 - val_acc: 0.7042\n",
      "Epoch 30/50\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.7485 - acc: 0.6671 - val_loss: 0.7860 - val_acc: 0.6976\n",
      "Epoch 31/50\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.7377 - acc: 0.6694 - val_loss: 0.7801 - val_acc: 0.7034\n",
      "Epoch 32/50\n",
      "4680/4680 [==============================] - 2s 451us/step - loss: 0.7349 - acc: 0.6793 - val_loss: 0.7048 - val_acc: 0.7301\n",
      "Epoch 33/50\n",
      "4680/4680 [==============================] - 2s 449us/step - loss: 0.7357 - acc: 0.6733 - val_loss: 0.7926 - val_acc: 0.7036\n",
      "Epoch 34/50\n",
      "4680/4680 [==============================] - 2s 451us/step - loss: 0.7303 - acc: 0.6827 - val_loss: 0.7634 - val_acc: 0.7215\n",
      "Epoch 35/50\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.7182 - acc: 0.6929 - val_loss: 0.6875 - val_acc: 0.7377\n",
      "Epoch 36/50\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.7283 - acc: 0.6808 - val_loss: 0.7160 - val_acc: 0.7279\n",
      "Epoch 37/50\n",
      "4680/4680 [==============================] - 2s 454us/step - loss: 0.7070 - acc: 0.7015 - val_loss: 0.7283 - val_acc: 0.7327\n",
      "Epoch 38/50\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.6993 - acc: 0.6947 - val_loss: 0.9741 - val_acc: 0.6661\n",
      "Epoch 39/50\n",
      "4680/4680 [==============================] - 2s 451us/step - loss: 0.6821 - acc: 0.7083 - val_loss: 0.7185 - val_acc: 0.7457\n",
      "Epoch 40/50\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.6908 - acc: 0.7096 - val_loss: 0.9083 - val_acc: 0.6800\n",
      "Epoch 41/50\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.6632 - acc: 0.7241 - val_loss: 0.8308 - val_acc: 0.7074\n",
      "Epoch 42/50\n",
      "4680/4680 [==============================] - 2s 451us/step - loss: 0.6690 - acc: 0.7209 - val_loss: 0.8878 - val_acc: 0.6934\n",
      "Epoch 43/50\n",
      "4680/4680 [==============================] - 2s 451us/step - loss: 0.6593 - acc: 0.7203 - val_loss: 0.9884 - val_acc: 0.6683\n",
      "Epoch 44/50\n",
      "4680/4680 [==============================] - 2s 451us/step - loss: 0.6456 - acc: 0.7288 - val_loss: 1.0632 - val_acc: 0.6484\n",
      "Epoch 45/50\n",
      "4680/4680 [==============================] - 2s 454us/step - loss: 0.6438 - acc: 0.7331 - val_loss: 0.9043 - val_acc: 0.6967\n",
      "Epoch 46/50\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.6407 - acc: 0.7284 - val_loss: 0.9007 - val_acc: 0.7091\n",
      "Epoch 47/50\n",
      "4680/4680 [==============================] - 2s 456us/step - loss: 0.6363 - acc: 0.7348 - val_loss: 0.9560 - val_acc: 0.6900\n",
      "Epoch 48/50\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.6257 - acc: 0.7408 - val_loss: 1.1252 - val_acc: 0.6568\n",
      "Epoch 49/50\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.6210 - acc: 0.7393 - val_loss: 0.9180 - val_acc: 0.7169\n",
      "Epoch 50/50\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.6106 - acc: 0.7451 - val_loss: 1.0308 - val_acc: 0.6815\n"
     ]
    }
   ],
   "source": [
    "model_1.fit(bal_train_x1, \n",
    "          bal_train_lab, \n",
    "          batch_size=64, \n",
    "          epochs=50, \n",
    "          verbose=1, \n",
    "          validation_data=(val_1, val_lab))\n",
    "#冻结model参数\n",
    "for lay in model_1.layers:\n",
    "    lay.trainable = False\n",
    "#为了连入新的model，将最后两层pop出\n",
    "# model_1.pop()\n",
    "# model_1.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A1价格变化关于A3历史价格的模型(训练)\n",
    "- 从训练结果可以看出最终在训练集正确率约68%,验证集正确率约48%,已经强于随机猜测,虽然发生过拟合,也是可以进行参考的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4680 samples, validate on 7491 samples\n",
      "Epoch 1/30\n",
      "4680/4680 [==============================] - 4s 803us/step - loss: 1.1208 - acc: 0.4239 - val_loss: 0.8568 - val_acc: 0.5318\n",
      "Epoch 2/30\n",
      "4680/4680 [==============================] - 2s 454us/step - loss: 1.0112 - acc: 0.4594 - val_loss: 0.8874 - val_acc: 0.4803\n",
      "Epoch 3/30\n",
      "4680/4680 [==============================] - 2s 449us/step - loss: 0.9914 - acc: 0.4835 - val_loss: 0.8455 - val_acc: 0.5061\n",
      "Epoch 4/30\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.9716 - acc: 0.4872 - val_loss: 0.9138 - val_acc: 0.4592\n",
      "Epoch 5/30\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.9452 - acc: 0.5188 - val_loss: 0.8947 - val_acc: 0.4688\n",
      "Epoch 6/30\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.9390 - acc: 0.5203 - val_loss: 0.9428 - val_acc: 0.4509\n",
      "Epoch 7/30\n",
      "4680/4680 [==============================] - 2s 455us/step - loss: 0.9282 - acc: 0.5308 - val_loss: 0.9457 - val_acc: 0.4666\n",
      "Epoch 8/30\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.9208 - acc: 0.5425 - val_loss: 0.9577 - val_acc: 0.4719\n",
      "Epoch 9/30\n",
      "4680/4680 [==============================] - 2s 451us/step - loss: 0.9140 - acc: 0.5588 - val_loss: 0.9450 - val_acc: 0.4684\n",
      "Epoch 10/30\n",
      "4680/4680 [==============================] - 2s 454us/step - loss: 0.9032 - acc: 0.5618 - val_loss: 0.9566 - val_acc: 0.4828\n",
      "Epoch 11/30\n",
      "4680/4680 [==============================] - 2s 451us/step - loss: 0.8966 - acc: 0.5654 - val_loss: 0.9743 - val_acc: 0.4893\n",
      "Epoch 12/30\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.8848 - acc: 0.5763 - val_loss: 0.9331 - val_acc: 0.5103\n",
      "Epoch 13/30\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.8773 - acc: 0.5833 - val_loss: 1.0195 - val_acc: 0.4886\n",
      "Epoch 14/30\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.8663 - acc: 0.5876 - val_loss: 1.0417 - val_acc: 0.4735\n",
      "Epoch 15/30\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.8609 - acc: 0.5983 - val_loss: 1.0279 - val_acc: 0.4811\n",
      "Epoch 16/30\n",
      "4680/4680 [==============================] - 2s 451us/step - loss: 0.8564 - acc: 0.5991 - val_loss: 1.0406 - val_acc: 0.4890\n",
      "Epoch 17/30\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.8384 - acc: 0.6081 - val_loss: 1.0701 - val_acc: 0.4819\n",
      "Epoch 18/30\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.8229 - acc: 0.6199 - val_loss: 1.0518 - val_acc: 0.5178\n",
      "Epoch 19/30\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.8343 - acc: 0.6079 - val_loss: 1.0657 - val_acc: 0.5109\n",
      "Epoch 20/30\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.8119 - acc: 0.6235 - val_loss: 0.9925 - val_acc: 0.5318\n",
      "Epoch 21/30\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.8036 - acc: 0.6269 - val_loss: 1.1953 - val_acc: 0.4887\n",
      "Epoch 22/30\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.7941 - acc: 0.6372 - val_loss: 1.1593 - val_acc: 0.4917\n",
      "Epoch 23/30\n",
      "4680/4680 [==============================] - 2s 449us/step - loss: 0.7852 - acc: 0.6455 - val_loss: 1.0716 - val_acc: 0.5106\n",
      "Epoch 24/30\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.7700 - acc: 0.6553 - val_loss: 1.2749 - val_acc: 0.4642\n",
      "Epoch 25/30\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.7672 - acc: 0.6541 - val_loss: 1.2212 - val_acc: 0.4848\n",
      "Epoch 26/30\n",
      "4680/4680 [==============================] - 2s 451us/step - loss: 0.7616 - acc: 0.6618 - val_loss: 1.2068 - val_acc: 0.4909\n",
      "Epoch 27/30\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.7469 - acc: 0.6690 - val_loss: 1.1166 - val_acc: 0.5123\n",
      "Epoch 28/30\n",
      "4680/4680 [==============================] - 2s 450us/step - loss: 0.7354 - acc: 0.6756 - val_loss: 1.2372 - val_acc: 0.5009\n",
      "Epoch 29/30\n",
      "4680/4680 [==============================] - 2s 453us/step - loss: 0.7341 - acc: 0.6786 - val_loss: 1.3238 - val_acc: 0.4865\n",
      "Epoch 30/30\n",
      "4680/4680 [==============================] - 2s 452us/step - loss: 0.7207 - acc: 0.6861 - val_loss: 1.3572 - val_acc: 0.4831\n"
     ]
    }
   ],
   "source": [
    "model_2.fit(bal_train_x2, \n",
    "          bal_train_lab, \n",
    "          batch_size=64, \n",
    "          epochs=30, \n",
    "          verbose=1, \n",
    "          validation_data=(val_2, val_lab))\n",
    "#冻结model参数\n",
    "for lay in model_2.layers:\n",
    "    lay.trainable = False\n",
    "#为了连入新的model，将最后两层pop出\n",
    "# model_2.pop()\n",
    "# model_2.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 模型的组合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将前两个model的输出(含义是各类别的概率)用contact的方式连接到一个整体的model中，作为输入\n",
    "- 这里已经冻结了前两个模型的参数,之后不能通过back-prop更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_6 (Merge)              (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                70        \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 28,041\n",
      "Trainable params: 103\n",
      "Non-trainable params: 27,938\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:2: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Merge([model_1,model_2],mode='concat',concat_axis=1))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "model.compile(optimizer=Adam(),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 训练整体的model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练结果, 在训练集上发生一定过拟合,正确率达到84%, 在验证集上正确率达到65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4680 samples, validate on 7491 samples\n",
      "Epoch 1/20\n",
      "4680/4680 [==============================] - 5s 1ms/step - loss: 1.1647 - acc: 0.3556 - val_loss: 1.3575 - val_acc: 0.0263\n",
      "Epoch 2/20\n",
      "4680/4680 [==============================] - 3s 592us/step - loss: 1.0152 - acc: 0.4575 - val_loss: 1.2220 - val_acc: 0.0657\n",
      "Epoch 3/20\n",
      "4680/4680 [==============================] - 3s 589us/step - loss: 0.8913 - acc: 0.7353 - val_loss: 1.1087 - val_acc: 0.4929\n",
      "Epoch 4/20\n",
      "4680/4680 [==============================] - 3s 592us/step - loss: 0.7577 - acc: 0.8124 - val_loss: 0.9770 - val_acc: 0.5723\n",
      "Epoch 5/20\n",
      "4680/4680 [==============================] - 3s 590us/step - loss: 0.6390 - acc: 0.8308 - val_loss: 0.9188 - val_acc: 0.6054\n",
      "Epoch 6/20\n",
      "4680/4680 [==============================] - 3s 589us/step - loss: 0.5646 - acc: 0.8269 - val_loss: 0.9124 - val_acc: 0.6239\n",
      "Epoch 7/20\n",
      "4680/4680 [==============================] - 3s 590us/step - loss: 0.5173 - acc: 0.8310 - val_loss: 0.9379 - val_acc: 0.6301\n",
      "Epoch 8/20\n",
      "4680/4680 [==============================] - 3s 592us/step - loss: 0.4925 - acc: 0.8303 - val_loss: 0.9509 - val_acc: 0.6392\n",
      "Epoch 9/20\n",
      "4680/4680 [==============================] - 3s 594us/step - loss: 0.4724 - acc: 0.8318 - val_loss: 0.9790 - val_acc: 0.6401\n",
      "Epoch 10/20\n",
      "4680/4680 [==============================] - 3s 592us/step - loss: 0.4630 - acc: 0.8342 - val_loss: 1.0044 - val_acc: 0.6416\n",
      "Epoch 11/20\n",
      "4680/4680 [==============================] - 3s 588us/step - loss: 0.4538 - acc: 0.8346 - val_loss: 1.0256 - val_acc: 0.6422\n",
      "Epoch 12/20\n",
      "4680/4680 [==============================] - 3s 589us/step - loss: 0.4536 - acc: 0.8346 - val_loss: 1.0439 - val_acc: 0.6425\n",
      "Epoch 13/20\n",
      "4680/4680 [==============================] - 3s 590us/step - loss: 0.4416 - acc: 0.8417 - val_loss: 1.0898 - val_acc: 0.6368\n",
      "Epoch 14/20\n",
      "4680/4680 [==============================] - 3s 591us/step - loss: 0.4415 - acc: 0.8408 - val_loss: 1.0829 - val_acc: 0.6417\n",
      "Epoch 15/20\n",
      "4680/4680 [==============================] - 3s 590us/step - loss: 0.4474 - acc: 0.8359 - val_loss: 1.0945 - val_acc: 0.6420\n",
      "Epoch 16/20\n",
      "4680/4680 [==============================] - 3s 591us/step - loss: 0.4395 - acc: 0.8348 - val_loss: 1.0820 - val_acc: 0.6480\n",
      "Epoch 17/20\n",
      "4680/4680 [==============================] - 3s 591us/step - loss: 0.4305 - acc: 0.8417 - val_loss: 1.0962 - val_acc: 0.6470\n",
      "Epoch 18/20\n",
      "4680/4680 [==============================] - 3s 589us/step - loss: 0.4459 - acc: 0.8312 - val_loss: 1.1234 - val_acc: 0.6441\n",
      "Epoch 19/20\n",
      "4680/4680 [==============================] - 3s 590us/step - loss: 0.4398 - acc: 0.8370 - val_loss: 1.1278 - val_acc: 0.6438\n",
      "Epoch 20/20\n",
      "4680/4680 [==============================] - 3s 594us/step - loss: 0.4382 - acc: 0.8378 - val_loss: 1.1278 - val_acc: 0.6465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8e4284a90>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([bal_train_x1, bal_train_x2], \n",
    "          bal_train_lab, \n",
    "          batch_size=64, \n",
    "          epochs=20, \n",
    "          verbose=1, \n",
    "          validation_data=([val_1, val_2], val_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 预测效果分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正确率与召回率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "组合模型在平衡后的训练集上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4680/4680 [==============================] - 1s 208us/step\n",
      "precision :  [0.8191489361702128, 0.9085684430512017, 0.8462757527733756]\n",
      "recall :  [0.8787446504992867, 0.9259850905218318, 0.7628571428571429]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_classes([bal_train_x1,bal_train_x2], batch_size=64, verbose=1)\n",
    "\n",
    "cal_result(bal_train_y1, prediction, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照先验概率随机猜测的正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02266355140186916\n",
      "0.9544726301735648\n",
      "0.022863818424566088\n"
     ]
    }
   ],
   "source": [
    "print(679 / (679 + 28596 + 685))\n",
    "print(28596 / (679 + 28596 + 685))\n",
    "print(685 / (679 + 28596 + 685))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "组合模型在测试集上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29960/29960 [==============================] - 7s 230us/step\n",
      "precision :  [0.04436074492571668, 0.972741712353333, 0.03954802259887006]\n",
      "recall :  [0.3122238586156112, 0.6639040425234298, 0.327007299270073]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_classes([test_1,test_2], batch_size=64, verbose=1)\n",
    "\n",
    "cal_result(test_y1, prediction, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1历史数据预测A1变化的单一模型在测试集上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29960/29960 [==============================] - 4s 117us/step\n",
      "precision :  [0.04556589906908378, 0.9698337976750888, 0.03616600790513834]\n",
      "recall :  [0.27393225331369664, 0.7060428031892573, 0.2671532846715328]\n"
     ]
    }
   ],
   "source": [
    "prediction = model_1.predict_classes(test_1, batch_size=64, verbose=1)\n",
    "\n",
    "cal_result(test_y1, prediction, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A3历史数据预测A1变化的单一模型在测试集上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29960/29960 [==============================] - 3s 116us/step\n",
      "precision :  [0.03636170889430722, 0.9785428791809831, 0.035429300989466964]\n",
      "recall :  [0.5051546391752577, 0.48800531542873127, 0.32408759124087594]\n"
     ]
    }
   ],
   "source": [
    "prediction = model_2.predict_classes(test_2, batch_size=64, verbose=1)\n",
    "\n",
    "cal_result(test_y1, prediction, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 结论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 由上述正确率召回率可以看出, 进行组合后的模型,正确率和召回率均优越于单一模型, 组合模型在上涨和下跌数据上的正确率是按照先验概率随机猜测的两倍, 且召回率相较于单一模型有提升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
